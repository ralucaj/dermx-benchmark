{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07824454",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0726a6a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, DirectoryIterator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.applications.resnet import preprocess_input as resnet_preprocessing\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import CSVLogger, EarlyStopping\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.errors import ResourceExhaustedError\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "def calc_class_weights(train_iterator):\n",
    "    \"\"\"\n",
    "    Calculate class weighs dictionary to use as input for the cnn training. This is useful if the training set is\n",
    "    imbalanced.\n",
    "\n",
    "    The weight of class \"i\" is calculated as the number of samples in the most populated class divided by the number of\n",
    "    samples in class i (max_class_frequency / class_frequency).\n",
    "    Note that the class weights are capped at 10. This is done in order to avoid placing too much weight on\n",
    "    small fraction of the dataset. For the same reason, the weight is set to 1 for any class in the training set that\n",
    "    contains fewer than 5 samples.\n",
    "\n",
    "    :param class_counts: A list with the number of files for each class.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # Fixed parameters\n",
    "    class_counts = np.unique(train_iterator.classes, return_counts=True)\n",
    "    class_weights = []\n",
    "    max_freq = max(class_counts[1])\n",
    "    class_weights = [max_freq / count for count in class_counts[1]]\n",
    "    \n",
    "    print(\"Classes: \" + str(class_counts[0]))\n",
    "    print(\"Samples per class: \" + str(class_counts[1]))\n",
    "    print(\"Class weights: \" + str(class_weights))\n",
    "\n",
    "    return class_weights\n",
    "\n",
    "\n",
    "def unfreeze_layers(model, last_fixed_layer):\n",
    "    # Retrieve the index of the last fixed layer and add 1 so that it is also set to not trainable\n",
    "    first_trainable = model.layers.index(model.get_layer(last_fixed_layer)) + 1\n",
    "\n",
    "    # Set which layers are trainable.\n",
    "    for layer_idx, layer in enumerate(model.layers):\n",
    "        if not isinstance(layer, BatchNormalization):\n",
    "            layer.trainable = layer_idx >= first_trainable\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(rotation, shear, zoom, brightness, lr, last_fixed_layer, batch_size, idx):\n",
    "    model_name = f'resnet50_{idx}'\n",
    "    if os.path.exists(Path('.') / (model_name + '.h5')):\n",
    "        print(f'{model_name} already trained')\n",
    "        return\n",
    "    print(f'Now training {model_name}')\n",
    "    \n",
    "    train_generator = ImageDataGenerator(\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        rotation_range=rotation,\n",
    "        shear_range=shear,\n",
    "        zoom_range=zoom,\n",
    "        brightness_range=brightness,\n",
    "        fill_mode='nearest',\n",
    "        preprocessing_function=resnet_preprocessing,\n",
    "    )\n",
    "    train_iterator = train_generator.flow_from_directory(\n",
    "        '/home/ubuntu/store/internal-neurips/full', \n",
    "        target_size=(300, 400),\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size,\n",
    "        follow_links=True,\n",
    "        interpolation='bilinear',\n",
    "    )\n",
    "    \n",
    "    loss_weights = calc_class_weights(train_iterator)\n",
    "\n",
    "    base_model = ResNet50(include_top=False, weights='imagenet', input_shape=(300, 400, 3))\n",
    "    top_model = Flatten()(base_model.output)\n",
    "    top_model = Dense(6, activation='softmax', name='diagnosis')(top_model)\n",
    "    model = Model(inputs=base_model.input, outputs=top_model)\n",
    "    model = unfreeze_layers(model, last_fixed_layer)\n",
    "    \n",
    "    optimiser = Adam(lr=lr)\n",
    "    model.compile(\n",
    "        optimizer=optimiser,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'],\n",
    "        loss_weights=loss_weights,\n",
    "    )\n",
    "    \n",
    "    logger = CSVLogger(model_name + '.csv')\n",
    "\n",
    "    model.fit(\n",
    "        x=train_iterator,\n",
    "        batch_size=batch_size,\n",
    "        epochs=30,\n",
    "        verbose=True,\n",
    "        class_weight=dict(zip(range(6), loss_weights)),\n",
    "        workers=8,\n",
    "        callbacks=[logger]\n",
    "    )\n",
    "    model.save(model_name + '.h5')\n",
    "    \n",
    "for idx in range(5):\n",
    "    model_name = train_model(20, 0, 0.25, [0.25, 1], 0.01, 'conv5_block2_add', 64, idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2ad3fe",
   "metadata": {},
   "source": [
    "## Validate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a25f059d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50_0 already validated\n",
      "resnet50_2 already validated\n",
      "resnet50_1 already validated\n",
      "resnet50_4 already validated\n",
      "resnet50_3 already validated\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, DirectoryIterator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.applications.resnet import preprocess_input as resnet_preprocessing\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import CSVLogger, EarlyStopping\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.errors import ResourceExhaustedError\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "base_path = \"/home/ubuntu/store/resnet-final-size\"\n",
    "model_names = glob.glob(\"/home/ubuntu/store/resnet-final-size/*.h5\")\n",
    "\n",
    "for model_path in model_names:\n",
    "    model_name = Path(model_path).stem\n",
    "    if os.path.exists(Path(base_path) / (model_name + '_preds.csv')):\n",
    "        print(f'{model_name} already validated')\n",
    "        continue\n",
    "    print('Now validating', model_name)\n",
    "    valid_generator = ImageDataGenerator(\n",
    "        fill_mode='nearest',\n",
    "        preprocessing_function=resnet_preprocessing\n",
    "    )\n",
    "    valid_iterator = valid_generator.flow_from_directory(\n",
    "        '/home/ubuntu/store/DermX-test-set/test', \n",
    "        batch_size=8, \n",
    "        target_size=(300, 400),\n",
    "        class_mode='categorical',\n",
    "        follow_links=True,\n",
    "        interpolation='bilinear',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    model = load_model(Path(model_path))\n",
    "    preds = [np.argmax(pred) for pred in model.predict(valid_iterator)]\n",
    "    actual = valid_iterator.labels\n",
    "    preds_df = pd.DataFrame.from_dict({'actual': actual, 'pred': preds, 'filenames': valid_iterator.filenames}).to_pickle(Path(base_path) / (model_name + '_preds.csv'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df466585",
   "metadata": {},
   "source": [
    "## Compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2856a82b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>resnet50_3_preds</th>\n",
       "      <td>0.380841</td>\n",
       "      <td>0.303244</td>\n",
       "      <td>0.263395</td>\n",
       "      <td>566</td>\n",
       "      <td>0.318021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet50_2_preds</th>\n",
       "      <td>0.399679</td>\n",
       "      <td>0.301546</td>\n",
       "      <td>0.275586</td>\n",
       "      <td>566</td>\n",
       "      <td>0.316254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet50_0_preds</th>\n",
       "      <td>0.420597</td>\n",
       "      <td>0.373788</td>\n",
       "      <td>0.345990</td>\n",
       "      <td>566</td>\n",
       "      <td>0.390459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet50_1_preds</th>\n",
       "      <td>0.373701</td>\n",
       "      <td>0.361956</td>\n",
       "      <td>0.356411</td>\n",
       "      <td>566</td>\n",
       "      <td>0.378092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet50_4_preds</th>\n",
       "      <td>0.430262</td>\n",
       "      <td>0.298456</td>\n",
       "      <td>0.267258</td>\n",
       "      <td>566</td>\n",
       "      <td>0.312721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  precision    recall  f1-score  support  accuracy\n",
       "resnet50_3_preds   0.380841  0.303244  0.263395      566  0.318021\n",
       "resnet50_2_preds   0.399679  0.301546  0.275586      566  0.316254\n",
       "resnet50_0_preds   0.420597  0.373788  0.345990      566  0.390459\n",
       "resnet50_1_preds   0.373701  0.361956  0.356411      566  0.378092\n",
       "resnet50_4_preds   0.430262  0.298456  0.267258      566  0.312721"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path = \"/home/ubuntu/store/resnet-final\"\n",
    "model_preds = glob.glob(\"/home/ubuntu/store/resnet-final-size/*_preds.csv\")\n",
    "model_comparison_dict = {}\n",
    "\n",
    "for model_pred in model_preds:\n",
    "    model_preds_df = pd.read_pickle(Path(model_pred))\n",
    "    model_comparison_dict[Path(model_pred).stem] = classification_report(\n",
    "        model_preds_df['actual'], \n",
    "        model_preds_df['pred'],\n",
    "        labels=[0, 1, 2, 3, 4, 5],\n",
    "        target_names=['acne', 'actinic_keratosis', 'psoriasis_no_pustular', 'seborrheic_dermatitis', 'vitiligo', 'wart'],\n",
    "        output_dict=True\n",
    "    )['macro avg']\n",
    "    model_comparison_dict[Path(model_pred).stem]['accuracy'] = len(model_preds_df[model_preds_df['actual'] == model_preds_df['pred']]) / len(model_preds_df)\n",
    "\n",
    "model_comparison_df = pd.DataFrame.from_dict(model_comparison_dict, orient='index')\n",
    "model_comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c452ba5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_5",
   "language": "python",
   "name": "tf2_5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
