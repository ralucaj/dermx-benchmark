{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07824454",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0726a6a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now training resnet50_0\n",
      "Found 3214 images belonging to 6 classes.\n",
      "Classes: [0 1 2 3 4 5]\n",
      "Samples per class: [1177  165  975  113  178  606]\n",
      "Class weights: [1.0, 7.133333333333334, 1.2071794871794872, 10.415929203539823, 6.612359550561798, 1.9422442244224423]\n",
      "Epoch 1/30\n",
      "51/51 [==============================] - 32s 636ms/step - loss: 112.2557 - accuracy: 0.6920\n",
      "Epoch 3/30\n",
      "51/51 [==============================] - 32s 633ms/step - loss: 42.0273 - accuracy: 0.7206\n",
      "Epoch 4/30\n",
      "51/51 [==============================] - 41s 803ms/step - loss: 31.0296 - accuracy: 0.7595\n",
      "Epoch 5/30\n",
      "51/51 [==============================] - 33s 643ms/step - loss: 23.1588 - accuracy: 0.7747\n",
      "Epoch 6/30\n",
      "51/51 [==============================] - 33s 638ms/step - loss: 17.3164 - accuracy: 0.8006\n",
      "Epoch 7/30\n",
      "51/51 [==============================] - 32s 631ms/step - loss: 16.9548 - accuracy: 0.8158\n",
      "Epoch 8/30\n",
      "51/51 [==============================] - 32s 634ms/step - loss: 15.5116 - accuracy: 0.8177\n",
      "Epoch 9/30\n",
      "51/51 [==============================] - 33s 639ms/step - loss: 11.8897 - accuracy: 0.8426\n",
      "Epoch 10/30\n",
      "51/51 [==============================] - 33s 642ms/step - loss: 9.2400 - accuracy: 0.8587\n",
      "Epoch 11/30\n",
      "51/51 [==============================] - 33s 639ms/step - loss: 8.7672 - accuracy: 0.8709\n",
      "Epoch 12/30\n",
      "51/51 [==============================] - 32s 632ms/step - loss: 6.8714 - accuracy: 0.8780\n",
      "Epoch 13/30\n",
      "51/51 [==============================] - 33s 638ms/step - loss: 7.3055 - accuracy: 0.8783\n",
      "Epoch 14/30\n",
      "51/51 [==============================] - 32s 637ms/step - loss: 5.5673 - accuracy: 0.8849\n",
      "Epoch 15/30\n",
      "51/51 [==============================] - 33s 639ms/step - loss: 5.6379 - accuracy: 0.8864\n",
      "Epoch 16/30\n",
      "51/51 [==============================] - 33s 638ms/step - loss: 4.3902 - accuracy: 0.8989\n",
      "Epoch 17/30\n",
      "51/51 [==============================] - 33s 643ms/step - loss: 4.9440 - accuracy: 0.8939\n",
      "Epoch 18/30\n",
      "51/51 [==============================] - 33s 643ms/step - loss: 3.5235 - accuracy: 0.9104\n",
      "Epoch 19/30\n",
      "51/51 [==============================] - 32s 635ms/step - loss: 4.0100 - accuracy: 0.8976\n",
      "Epoch 20/30\n",
      "51/51 [==============================] - 33s 640ms/step - loss: 3.7158 - accuracy: 0.9073\n",
      "Epoch 21/30\n",
      "51/51 [==============================] - 33s 641ms/step - loss: 3.9283 - accuracy: 0.9070\n",
      "Epoch 22/30\n",
      "51/51 [==============================] - 33s 643ms/step - loss: 3.2891 - accuracy: 0.9259\n",
      "Epoch 23/30\n",
      "51/51 [==============================] - 33s 640ms/step - loss: 3.6442 - accuracy: 0.9063\n",
      "Epoch 24/30\n",
      "51/51 [==============================] - 32s 635ms/step - loss: 3.3509 - accuracy: 0.9197\n",
      "Epoch 25/30\n",
      "51/51 [==============================] - 32s 629ms/step - loss: 3.5799 - accuracy: 0.9032\n",
      "Epoch 26/30\n",
      "51/51 [==============================] - 32s 632ms/step - loss: 4.4764 - accuracy: 0.9039\n",
      "Epoch 27/30\n",
      "51/51 [==============================] - 33s 643ms/step - loss: 3.8206 - accuracy: 0.9029\n",
      "Epoch 28/30\n",
      "51/51 [==============================] - 33s 638ms/step - loss: 3.4412 - accuracy: 0.9235\n",
      "Epoch 29/30\n",
      "51/51 [==============================] - 33s 643ms/step - loss: 3.8888 - accuracy: 0.9063\n",
      "Epoch 30/30\n",
      "51/51 [==============================] - 32s 634ms/step - loss: 5.0841 - accuracy: 0.8970\n",
      "Now training resnet50_1\n",
      "Found 3214 images belonging to 6 classes.\n",
      "Classes: [0 1 2 3 4 5]\n",
      "Samples per class: [1177  165  975  113  178  606]\n",
      "Class weights: [1.0, 7.133333333333334, 1.2071794871794872, 10.415929203539823, 6.612359550561798, 1.9422442244224423]\n",
      "Epoch 1/30\n",
      "51/51 [==============================] - 33s 639ms/step - loss: 268.5239 - accuracy: 0.5246\n",
      "Epoch 2/30\n",
      "51/51 [==============================] - 32s 637ms/step - loss: 44.2017 - accuracy: 0.6942\n",
      "Epoch 3/30\n",
      "51/51 [==============================] - 32s 636ms/step - loss: 25.3279 - accuracy: 0.7449\n",
      "Epoch 4/30\n",
      "51/51 [==============================] - 32s 636ms/step - loss: 17.6818 - accuracy: 0.7984\n",
      "Epoch 5/30\n",
      "51/51 [==============================] - 33s 649ms/step - loss: 16.0643 - accuracy: 0.7813\n",
      "Epoch 6/30\n",
      "51/51 [==============================] - 32s 636ms/step - loss: 18.8304 - accuracy: 0.7940\n",
      "Epoch 7/30\n",
      "51/51 [==============================] - 33s 637ms/step - loss: 12.6121 - accuracy: 0.8283\n",
      "Epoch 8/30\n",
      "51/51 [==============================] - 33s 645ms/step - loss: 9.2215 - accuracy: 0.8379\n",
      "Epoch 9/30\n",
      "51/51 [==============================] - 33s 637ms/step - loss: 9.0925 - accuracy: 0.8401\n",
      "Epoch 10/30\n",
      "51/51 [==============================] - 33s 651ms/step - loss: 8.3029 - accuracy: 0.8444\n",
      "Epoch 11/30\n",
      "51/51 [==============================] - 33s 642ms/step - loss: 7.3414 - accuracy: 0.8479\n",
      "Epoch 12/30\n",
      "51/51 [==============================] - 32s 632ms/step - loss: 5.5656 - accuracy: 0.8734\n",
      "Epoch 13/30\n",
      "51/51 [==============================] - 32s 627ms/step - loss: 5.5897 - accuracy: 0.8643\n",
      "Epoch 14/30\n",
      "51/51 [==============================] - 32s 634ms/step - loss: 6.6209 - accuracy: 0.8575\n",
      "Epoch 15/30\n",
      "51/51 [==============================] - 32s 635ms/step - loss: 3.7618 - accuracy: 0.9020\n",
      "Epoch 16/30\n",
      "51/51 [==============================] - 33s 638ms/step - loss: 4.7439 - accuracy: 0.8712\n",
      "Epoch 17/30\n",
      "51/51 [==============================] - 32s 637ms/step - loss: 4.3356 - accuracy: 0.8799\n",
      "Epoch 18/30\n",
      "51/51 [==============================] - 32s 637ms/step - loss: 5.2000 - accuracy: 0.8740\n",
      "Epoch 19/30\n",
      "51/51 [==============================] - 32s 637ms/step - loss: 4.5250 - accuracy: 0.8855\n",
      "Epoch 20/30\n",
      "51/51 [==============================] - 32s 635ms/step - loss: 3.7537 - accuracy: 0.8958\n",
      "Epoch 21/30\n",
      "51/51 [==============================] - 32s 634ms/step - loss: 3.7881 - accuracy: 0.8833\n",
      "Epoch 22/30\n",
      "51/51 [==============================] - 33s 639ms/step - loss: 3.9965 - accuracy: 0.8802\n",
      "Epoch 23/30\n",
      "51/51 [==============================] - 33s 641ms/step - loss: 3.8793 - accuracy: 0.8911\n",
      "Epoch 24/30\n",
      "51/51 [==============================] - 32s 637ms/step - loss: 3.0898 - accuracy: 0.8874\n",
      "Epoch 25/30\n",
      "51/51 [==============================] - 33s 646ms/step - loss: 4.1781 - accuracy: 0.8821\n",
      "Epoch 26/30\n",
      "51/51 [==============================] - 33s 647ms/step - loss: 3.1073 - accuracy: 0.9051\n",
      "Epoch 27/30\n",
      "51/51 [==============================] - 32s 633ms/step - loss: 3.4298 - accuracy: 0.9067\n",
      "Epoch 28/30\n",
      "51/51 [==============================] - 33s 646ms/step - loss: 2.9778 - accuracy: 0.9091\n",
      "Epoch 29/30\n",
      "27/51 [==============>...............] - ETA: 15s - loss: 2.8573 - accuracy: 0.9167"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, DirectoryIterator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.applications.resnet import preprocess_input as resnet_preprocessing\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import CSVLogger, EarlyStopping\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.errors import ResourceExhaustedError\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "def calc_class_weights(train_iterator):\n",
    "    \"\"\"\n",
    "    Calculate class weighs dictionary to use as input for the cnn training. This is useful if the training set is\n",
    "    imbalanced.\n",
    "\n",
    "    The weight of class \"i\" is calculated as the number of samples in the most populated class divided by the number of\n",
    "    samples in class i (max_class_frequency / class_frequency).\n",
    "    Note that the class weights are capped at 10. This is done in order to avoid placing too much weight on\n",
    "    small fraction of the dataset. For the same reason, the weight is set to 1 for any class in the training set that\n",
    "    contains fewer than 5 samples.\n",
    "\n",
    "    :param class_counts: A list with the number of files for each class.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # Fixed parameters\n",
    "    class_counts = np.unique(train_iterator.classes, return_counts=True)\n",
    "    class_weights = []\n",
    "    max_freq = max(class_counts[1])\n",
    "    class_weights = [max_freq / count for count in class_counts[1]]\n",
    "    \n",
    "    print(\"Classes: \" + str(class_counts[0]))\n",
    "    print(\"Samples per class: \" + str(class_counts[1]))\n",
    "    print(\"Class weights: \" + str(class_weights))\n",
    "\n",
    "    return class_weights\n",
    "\n",
    "\n",
    "def unfreeze_layers(model, last_fixed_layer):\n",
    "    # Retrieve the index of the last fixed layer and add 1 so that it is also set to not trainable\n",
    "    first_trainable = model.layers.index(model.get_layer(last_fixed_layer)) + 1\n",
    "\n",
    "    # Set which layers are trainable.\n",
    "    for layer_idx, layer in enumerate(model.layers):\n",
    "        if not isinstance(layer, BatchNormalization):\n",
    "            layer.trainable = layer_idx >= first_trainable\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(rotation, shear, zoom, brightness, lr, last_fixed_layer, batch_size, idx):\n",
    "    model_name = f'resnet50_{idx}'\n",
    "    if os.path.exists(Path('.') / (model_name + '.h5')):\n",
    "        print(f'{model_name} already trained')\n",
    "        return\n",
    "    print(f'Now training {model_name}')\n",
    "    \n",
    "    train_generator = ImageDataGenerator(\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        rotation_range=rotation,\n",
    "        shear_range=shear,\n",
    "        zoom_range=zoom,\n",
    "        brightness_range=brightness,\n",
    "        fill_mode='nearest',\n",
    "        preprocessing_function=resnet_preprocessing,\n",
    "    )\n",
    "    train_iterator = train_generator.flow_from_directory(\n",
    "        '/home/ubuntu/store/barankin-neurips/full', \n",
    "        target_size=(300, 400),\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size,\n",
    "        follow_links=True,\n",
    "        interpolation='bilinear',\n",
    "    )\n",
    "    \n",
    "    loss_weights = calc_class_weights(train_iterator)\n",
    "\n",
    "    base_model = ResNet50(include_top=False, weights='imagenet', input_shape=(300, 400, 3))\n",
    "    top_model = Flatten()(base_model.output)\n",
    "    top_model = Dense(6, activation='softmax', name='diagnosis')(top_model)\n",
    "    model = Model(inputs=base_model.input, outputs=top_model)\n",
    "    model = unfreeze_layers(model, last_fixed_layer)\n",
    "    \n",
    "    optimiser = Adam(lr=lr)\n",
    "    model.compile(\n",
    "        optimizer=optimiser,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'],\n",
    "        loss_weights=loss_weights,\n",
    "    )\n",
    "    \n",
    "    logger = CSVLogger(model_name + '.csv')\n",
    "\n",
    "    model.fit(\n",
    "        x=train_iterator,\n",
    "        batch_size=batch_size,\n",
    "        epochs=30,\n",
    "        verbose=True,\n",
    "        class_weight=dict(zip(range(6), loss_weights)),\n",
    "        workers=8,\n",
    "        callbacks=[logger]\n",
    "    )\n",
    "    model.save(model_name + '.h5')\n",
    "    \n",
    "for idx in range(5):\n",
    "    model_name = train_model(20, 0, 0.25, [0.25, 1], 0.01, 'conv5_block2_add', 64, idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2ad3fe",
   "metadata": {},
   "source": [
    "## Validate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a25f059d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50_0 already validated\n",
      "resnet50_2 already validated\n",
      "resnet50_1 already validated\n",
      "resnet50_4 already validated\n",
      "resnet50_3 already validated\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, DirectoryIterator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.applications.resnet import preprocess_input as resnet_preprocessing\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import CSVLogger, EarlyStopping\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.errors import ResourceExhaustedError\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "base_path = \"/home/ubuntu/store/resnet-final-size\"\n",
    "model_names = glob.glob(\"/home/ubuntu/store/resnet-final-size/*.h5\")\n",
    "\n",
    "for model_path in model_names:\n",
    "    model_name = Path(model_path).stem\n",
    "    if os.path.exists(Path(base_path) / (model_name + '_preds.csv')):\n",
    "        print(f'{model_name} already validated')\n",
    "        continue\n",
    "    print('Now validating', model_name)\n",
    "    valid_generator = ImageDataGenerator(\n",
    "        fill_mode='nearest',\n",
    "        preprocessing_function=resnet_preprocessing\n",
    "    )\n",
    "    valid_iterator = valid_generator.flow_from_directory(\n",
    "        '/home/ubuntu/store/DermX-test-set/test', \n",
    "        batch_size=8, \n",
    "        target_size=(300, 400),\n",
    "        class_mode='categorical',\n",
    "        follow_links=True,\n",
    "        interpolation='bilinear',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    model = load_model(Path(model_path))\n",
    "    preds = [np.argmax(pred) for pred in model.predict(valid_iterator)]\n",
    "    actual = valid_iterator.labels\n",
    "    preds_df = pd.DataFrame.from_dict({'actual': actual, 'pred': preds, 'filenames': valid_iterator.filenames}).to_pickle(Path(base_path) / (model_name + '_preds.csv'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df466585",
   "metadata": {},
   "source": [
    "## Compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2856a82b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>resnet50_3_preds</th>\n",
       "      <td>0.380841</td>\n",
       "      <td>0.303244</td>\n",
       "      <td>0.263395</td>\n",
       "      <td>566</td>\n",
       "      <td>0.318021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet50_2_preds</th>\n",
       "      <td>0.399679</td>\n",
       "      <td>0.301546</td>\n",
       "      <td>0.275586</td>\n",
       "      <td>566</td>\n",
       "      <td>0.316254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet50_0_preds</th>\n",
       "      <td>0.420597</td>\n",
       "      <td>0.373788</td>\n",
       "      <td>0.345990</td>\n",
       "      <td>566</td>\n",
       "      <td>0.390459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet50_1_preds</th>\n",
       "      <td>0.373701</td>\n",
       "      <td>0.361956</td>\n",
       "      <td>0.356411</td>\n",
       "      <td>566</td>\n",
       "      <td>0.378092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet50_4_preds</th>\n",
       "      <td>0.430262</td>\n",
       "      <td>0.298456</td>\n",
       "      <td>0.267258</td>\n",
       "      <td>566</td>\n",
       "      <td>0.312721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  precision    recall  f1-score  support  accuracy\n",
       "resnet50_3_preds   0.380841  0.303244  0.263395      566  0.318021\n",
       "resnet50_2_preds   0.399679  0.301546  0.275586      566  0.316254\n",
       "resnet50_0_preds   0.420597  0.373788  0.345990      566  0.390459\n",
       "resnet50_1_preds   0.373701  0.361956  0.356411      566  0.378092\n",
       "resnet50_4_preds   0.430262  0.298456  0.267258      566  0.312721"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path = \"/home/ubuntu/store/resnet-final\"\n",
    "model_preds = glob.glob(\"/home/ubuntu/store/resnet-final-size/*_preds.csv\")\n",
    "model_comparison_dict = {}\n",
    "\n",
    "for model_pred in model_preds:\n",
    "    model_preds_df = pd.read_pickle(Path(model_pred))\n",
    "    model_comparison_dict[Path(model_pred).stem] = classification_report(\n",
    "        model_preds_df['actual'], \n",
    "        model_preds_df['pred'],\n",
    "        labels=[0, 1, 2, 3, 4, 5],\n",
    "        target_names=['acne', 'actinic_keratosis', 'psoriasis_no_pustular', 'seborrheic_dermatitis', 'vitiligo', 'wart'],\n",
    "        output_dict=True\n",
    "    )['macro avg']\n",
    "    model_comparison_dict[Path(model_pred).stem]['accuracy'] = len(model_preds_df[model_preds_df['actual'] == model_preds_df['pred']]) / len(model_preds_df)\n",
    "\n",
    "model_comparison_df = pd.DataFrame.from_dict(model_comparison_dict, orient='index')\n",
    "model_comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c452ba5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_5",
   "language": "python",
   "name": "tf2_5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
