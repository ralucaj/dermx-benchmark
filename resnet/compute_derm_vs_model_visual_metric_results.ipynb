{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbbca051",
   "metadata": {},
   "source": [
    "This notebook computes all of the \"distances\" (the fuzzy logic scores for IOU, DICE, ...) between the GradCam maps produced by the final resNet50 model and the visual characterstics maps created by the derm. That is: \n",
    "\n",
    "```\n",
    "for each image i  \n",
    "  for each GradCam image i_gc  \n",
    "    for each derm d  \n",
    "      for each characteristic d_char  \n",
    "        compute the visual distance between i_gc and d_char \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da3b6100",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77f6d0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "\n",
    "# Path to the GradCam images.\n",
    "gradcam_main_path = Path('/home/ubuntu/store/resnet-final-size/visualisation/gradcam/')\n",
    "\n",
    "# Set path to the model used to create the visualisations.\n",
    "model_path = Path('resnet50_3')\n",
    "\n",
    "# Path to the masks create by the derms for the individual characteristics.\n",
    "derm_mask_main_path = Path('/home/ubuntu/store/masks/masks_resized')\n",
    "\n",
    "# Path to the rescaled test images.\n",
    "test_im_path = Path('/home/ubuntu/store/DermX-test-set/test/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8c2ca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_gradcam_path = gradcam_main_path / model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1037158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"Acne\",\n",
    "    \"Actinic keratosis\",\n",
    "    \"Psoriasis\",\n",
    "    \"Seborrheic dermatitis\",\n",
    "    \"Viral warts\",\n",
    "    \"Vitiligo\"\n",
    "]\n",
    "\n",
    "derms = [\n",
    "    'derm0',\n",
    "    'derm1',\n",
    "    'derm2',\n",
    "    'derm3',\n",
    "    'derm4',\n",
    "    'derm5',\n",
    "    'derm6',\n",
    "    'derm7',\n",
    "]\n",
    "\n",
    "chars = [\n",
    "    'closed-comedo',\n",
    "    'cyst',\n",
    "    'dermatoglyph-disruption',\n",
    "    'leukotrichia',\n",
    "    'macule',\n",
    "    'nodule',\n",
    "    'open-comedo',\n",
    "    'papule',\n",
    "    'patch',\n",
    "    'plaque',\n",
    "    'pustule',\n",
    "    'scale',\n",
    "    'scar',\n",
    "    'sun-damage',\n",
    "    'telangiectasia',\n",
    "    'thrombosed-capillaries'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dbd595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the paths to the derm masks. The resulting list is only used for a sanity check.\n",
    "derm_mask_paths = [p for p in derm_mask_main_path.iterdir() if p.suffix == '.png']\n",
    "derm_mask_paths[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11a1739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the paths to the test images. Only needed for visualization and debugging.\n",
    "test_img_paths = [p for p in Path(test_im_path).rglob('*.jpeg')]\n",
    "test_img_paths[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aec9b08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics supporting probabilistic segmentation maps\n",
    "fuzzy_and = lambda x,y: np.minimum(x,y)\n",
    "fuzzy_or = lambda x,y: np.maximum(x,y)\n",
    "fuzzy_not = lambda x: 1-x\n",
    "\n",
    "def pixel_metrics_fuzzy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Pixel-level metrics of segmentation accuracy following fuzzy logic operators.\n",
    "    \n",
    "    :param y_true: numpy.ndarray of reference segmentation, values in [0,1]\n",
    "    :param y_pred: numpy.ndarray of predicted segmentation, values in [0,1]\n",
    "\n",
    "    :return: a dictionary encoding the metrics\n",
    "    \"\"\"\n",
    "        \n",
    "    np.testing.assert_equal(y_true.shape, y_pred.shape, err_msg=\"Expecting \\\n",
    "    the reference and predicted segmentations to be of the same size.\")\n",
    "    \n",
    "    # Check the ranges\n",
    "    np.testing.assert_equal(np.logical_and(y_true >= 0, y_true <= 1).all(), True, err_msg=\"Expecting \\\n",
    "    the reference segmentations to be in the range 0 to 1.\")\n",
    "    np.testing.assert_equal(np.logical_and(y_pred >= 0, y_pred <= 1).all(), True, err_msg=\"Expecting \\\n",
    "    the predicted segmentations to be in the range 0 to 1.\")\n",
    "    \n",
    "    TP = fuzzy_and(y_true, y_pred).sum()\n",
    "    TN = fuzzy_and(fuzzy_not(y_true), fuzzy_not(y_pred)).sum()\n",
    "    union = fuzzy_or(y_true, y_pred).sum()\n",
    "    \n",
    "    metrics = {}\n",
    "    \n",
    "    # Summary metrics\n",
    "    metrics[\"iou\"] = TP / union\n",
    "    metrics[\"dice\"] = 2 * TP / ( y_true.sum() + y_pred.sum() ) \n",
    "    \n",
    "    # Positive class metrics\n",
    "    metrics[\"precision\"] = TP / y_pred.sum()\n",
    "    metrics[\"recall\"] = TP / y_true.sum()\n",
    "    \n",
    "    # Negative class metrics\n",
    "    metrics[\"negative_predictive_value\"] = TN / fuzzy_not(y_pred).sum()\n",
    "    metrics[\"specificity\"] = TN / fuzzy_not(y_true).sum()\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9255c438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_res(gradcam_image_path, derm_char_mask_path, interpolation_method=Image.NEAREST):\n",
    "    \"\"\"\n",
    "    Calculates the fuzzy logic metrics given the paths to a pair of input images.\n",
    "    The derm mask is resized to match the size of the gradcam image.\n",
    "    \n",
    "    Input:\n",
    "    - gradcam_image_path: Pathlib path to a gradCam image. The file is assumed to be in .npy format.\n",
    "    - derm_char_mask_path: Pathlib path to a derm annotation. The file is assumed to be in a format that can\n",
    "                           be opened by PIL.\n",
    "    - interpolation_method: String. The method used for interpolation when resizing the derm mask. Options are\n",
    "                            NEAREST, BOX, BILINEAR, HAMMING, BICUBIC, LANCZOS. Default is NEAREST.    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Open images.\n",
    "    gradcam_im = np.load(gradcam_image_path, allow_pickle=True)\n",
    "    mask_im = Image.open(derm_char_mask_path)\n",
    "    \n",
    "    # Resize the derm mask if its size does not match the size of the gradcam image.\n",
    "    if gradcam_im.shape != mask_im.size[::-1]:\n",
    "        # Note that resize uses (cols, rows) format, while .shape is in (rows, cols) format.\n",
    "        mask_im = mask_im.resize((gradcam_im.shape[::-1]), interpolation_method)\n",
    "    \n",
    "    # Corvert the derm mask to numpy format and normalize to [0, 1].\n",
    "    mask_im = np.asarray(mask_im) / 255\n",
    "  \n",
    "    res = pixel_metrics_fuzzy(mask_im, gradcam_im)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d610313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each image in the test set, calculate the value of the defined metrics given the GradCam image for a given\n",
    "# class and the outline made by a specific derm for a given characteristic. The result is stored in a defaultdict.\n",
    "# As a sanity check, the number of matches between GradCam images and derm annotations is also calculated.\n",
    "rec_dd = lambda: defaultdict(rec_dd)\n",
    "out_gradcam = rec_dd()\n",
    "hit_counter = 0\n",
    "\n",
    "# Set the method used for interpolation when resizing the derm annotations.\n",
    "interpolation = Image.NEAREST\n",
    "\n",
    "for p in test_img_paths:\n",
    "    for c in classes:\n",
    "        # Check if matching GradCam file file exists.\n",
    "        gc_path = full_gradcam_path / Path(p.stem + '_' + c + '.npy')\n",
    "        if gc_path.is_file():\n",
    "            for d in derms:\n",
    "                for ch in chars:\n",
    "                    # Check if this derm has created a mask for this characteristic.\n",
    "                    mask_path = derm_mask_main_path / Path(p.stem + '_' + d + '_2021-05-27-masks_' + ch + '.png') \n",
    "                    if mask_path.is_file():\n",
    "                        # Calculate the value of the metics given the GradCam image and the derm mask.\n",
    "                        gradcam_metric_val = calc_res(gc_path, mask_path, interpolation)\n",
    "                        out_gradcam[p.stem][c][d][ch] = gradcam_metric_val\n",
    "                        \n",
    "                        hit_counter += 1\n",
    "        else:\n",
    "            print('GradCam file missing for image: ', p)\n",
    "\n",
    "print(hit_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d5ce15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We expect that the value of the hit counter should be equal to the number of derm masks multiplied with the number\n",
    "# of classes.\n",
    "if len(derm_mask_paths)*6 != hit_counter:\n",
    "    print('Oh no, some files were not found. Expected/found: ', len(derm_mask_paths)*6, hit_counter)\n",
    "else:\n",
    "    print('GradCam images found for all derm annotations.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a2eb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_list(nested_dict):\n",
    "    # Transform the gradcam or lime defaultdict to a list of tuples.\n",
    "    \n",
    "    out = []\n",
    "    for im_name, class_dict in nested_dict.items():\n",
    "        for class_name, derm_dict in class_dict.items():\n",
    "            for derm_name, char_dict in derm_dict.items():\n",
    "                for char_name, metric_dict in char_dict.items():\n",
    "                    tmp = tuple(metric_dict.values())\n",
    "                    out.append( (im_name, class_name, derm_name, char_name) + tmp )\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e2cb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradcam_res_list = transform_to_list(out_gradcam)\n",
    "len(gradcam_res_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94729b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradcam_res_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed92cadc",
   "metadata": {},
   "source": [
    "## Make output dataFrames/csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe708bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['image_name',\n",
    "             'visualisation_class',\n",
    "             'derm',\n",
    "             'characteristic',\n",
    "             'iou',\n",
    "             'dice',\n",
    "             'precision',\n",
    "             'recall',\n",
    "             'negative_predictive_value',\n",
    "             'specificity'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722e3353",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradcam_df = pd.DataFrame.from_records(gradcam_res_list, columns=col_names)\n",
    "gradcam_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e67c7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataFrames\n",
    "model_name = str(model_path)\n",
    "gradcam_df.to_csv(model_name + \"_gradcam_scores.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2350c73f",
   "metadata": {},
   "source": [
    "# Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b31bd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = glob.glob('/home/ubuntu/store/resnet-final-size/*h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e1006df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = Path(model_names[4]).stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6e2f43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table(results_pred):\n",
    "    results_mean = results_pred.groupby('characteristic').mean()\n",
    "    results_std =  results_pred.groupby('characteristic').std()\n",
    "    \n",
    "    ### Add means\n",
    "    results_mean.loc['mean'] = results_mean.mean()\n",
    "    results_std.loc['mean']   = results_mean.mean()\n",
    "    \n",
    "    columns = results_mean.columns.to_list()\n",
    "\n",
    "    table_pred = results_mean\n",
    "    return table_pred\n",
    "\n",
    "class_map = {'0' : 'Acne' ,\n",
    "             '1' : 'Actinic keratosis',\n",
    "             '2' : 'Psoriasis' ,\n",
    "             '3' : 'Seborrheic dermatitis',\n",
    "             '4' : 'Viral warts',\n",
    "             '5' : 'Vitiligo'}\n",
    "\n",
    "filefolder = model_name + \"_gradcam_scores.csv\"\n",
    "predsfile = '/home/ubuntu/store/resnet-final-size/' + model_name + '_preds.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d37df477",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_subjects = pd.read_csv('./include_images_525.csv')\n",
    "filtered_subjects['image_id'] = filtered_subjects['image_id'].apply(lambda x: Path(x).stem)\n",
    "filtered_subjects = filtered_subjects.rename(columns={'image_id': 'image_name'})\n",
    "filtered_subjects = filtered_subjects.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b77105f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds = pd.read_pickle(predsfile)\n",
    "gradcam_df = pd.read_csv(filefolder)\n",
    "gradcam_df=gradcam_df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9602735",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds['pred'] =  df_preds['pred'].apply(lambda x: class_map[str(x)])\n",
    "df_preds['actual'] = df_preds['actual'].apply(lambda x: class_map[str(x)])\n",
    "df_preds['filenames'] = df_preds['filenames'].apply(lambda x: Path(x).stem)\n",
    "df_preds = df_preds.rename(columns={'filenames':'image_name'})\n",
    "df_preds = df_preds.merge(filtered_subjects, on = 'image_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1989ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.merge(gradcam_df,df_preds, on = 'image_name')\n",
    "\n",
    "results_pred = result[result.visualisation_class == result.pred]\n",
    "table_pred = get_table(results_pred)\n",
    "# Get it for actual\n",
    "results_actual = result[result.visualisation_class == result.actual  ]\n",
    "table_actual = get_table(results_actual)\n",
    "\n",
    "table_pred.to_pickle('./' + model_name + '_gradcam_visualisation_scores_pred.pkl')\n",
    "table_actual.to_pickle('./' + model_name + '_gradcam_visualisation_scores_actual.pkl')\n",
    "\n",
    "results_equal = result[ (result.actual == result.pred) & (result.visualisation_class == result.pred) ]\n",
    "table_equal = get_table(results_equal)\n",
    "\n",
    "results_diff = result[ (result.actual != result.pred) & (result.visualisation_class == result.pred) ]\n",
    "table_diff = get_table(results_diff)\n",
    "\n",
    "table_equal.to_pickle('./' + model_name + '_gradcam_visualisation_scores_equal.pkl')\n",
    "table_diff.to_pickle('./' + model_name + '_gradcam_visualisation_scores_diff.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcb20666",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_actual.to_pickle('resnet_results_actual.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9662757",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_equal = result[ (result.actual == result.pred) & (result.visualisation_class == result.pred) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea17ee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_diff = get_table(results_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e872f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_equal = get_table(results_equal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "219dd37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_diff = result[ (result.actual != result.pred) & (result.visualisation_class == result.pred) ]\n",
    "table_diff = get_table(results_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefc39a5",
   "metadata": {},
   "source": [
    "# Summarize all Results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ab5a3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet = pd.read_pickle('efficientnet_results_actual.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a61c424",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = pd.read_pickle('resnet_results_actual.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29fdea53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = efficientnet.merge(resnet, how = 'inner', on='image_name', suffixes=('_eff','_res'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6339d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in efficientnet.columns.tolist()[4:10]:\n",
    "    df_merge[m + '_delta'] = df_merge[m + '_res'] - df_merge[m + '_eff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51cd4c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iou_eff                            0.087306\n",
       "dice_eff                           0.143882\n",
       "precision_eff                      0.171179\n",
       "recall_eff                         0.298972\n",
       "negative_predictive_value_eff      0.887880\n",
       "specificity_eff                    0.801302\n",
       "iou_res                            0.058266\n",
       "dice_res                           0.103010\n",
       "precision_res                      0.160162\n",
       "recall_res                         0.189032\n",
       "negative_predictive_value_res      0.886545\n",
       "specificity_res                    0.888918\n",
       "iou_delta                         -0.029039\n",
       "dice_delta                        -0.040872\n",
       "precision_delta                   -0.011017\n",
       "recall_delta                      -0.109939\n",
       "negative_predictive_value_delta   -0.001335\n",
       "specificity_delta                  0.087616\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.groupby('characteristic_eff').mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d332fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}